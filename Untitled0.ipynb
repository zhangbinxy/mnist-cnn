{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "l2pAkWkhFW4J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import math\n",
        "import time\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EBCPFaEvJ2_G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_batches = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GuMCi9l9NGlI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_activations(t):\n",
        "  print(t.op.name,'',t.get_shape().as_list())\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-xmFDeKcNgIy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def inference(images):\n",
        "  parameters = []\n",
        "  with tf.name_scope('conv1') as scope:\n",
        "    kernel = tf.Variable(tf.truncated_normal([11,11,3,64],\n",
        "                                            dtype=tf.float32,stddev=1e-1),name='weights')\n",
        "    conv = tf.nn.conv2d(images,kernel,[1,4,4,1],padding='SAME')\n",
        "    biases = tf.Variable(tf.constant(0.0,shape=[64],dtype=tf.float32),trainable=True,name='biases')\n",
        "    bias = tf.nn.bias_add(conv,biases)\n",
        "    conv1 = tf.nn.relu(bias,name=scope)\n",
        "    print_activations(conv1)\n",
        "    parameters+=[kernel,biases]\n",
        "    \n",
        "  lrn1 = tf.nn.lrn(conv1,4,bias=1.0,alpha=0.001/9,beta=0.75,name='lrn1')\n",
        "  pool1 = tf.nn.max_pool(lrn1,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID',name='pool1')\n",
        "  print_activations(pool1)\n",
        "  \n",
        "  with tf.name_scope('conv2') as scope:\n",
        "    kernel = tf.Variable(tf.truncated_normal([5,5,64,192],\n",
        "                                            dtype=tf.float32,stddev=1e-1),name='weights')\n",
        "    conv = tf.nn.conv2d(pool1,kernel,[1,1,1,1],padding='SAME')\n",
        "    biases = tf.Variable(tf.constant(0.0,shape=[192],dtype=tf.float32),trainable=True,name='biases')\n",
        "    bias = tf.nn.bias_add(conv,biases)\n",
        "    conv2 = tf.nn.relu(bias,name=scope)\n",
        "    parameters+=[kernel,biases]\n",
        "    print_activations(conv2)\n",
        "  \n",
        "  lrn2 = tf.nn.lrn(conv2,4,bias=1.0,alpha=0.001/9,beta=0.75,name='lrn2')\n",
        "  pool2 = tf.nn.max_pool(lrn2,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID',name='pool2')\n",
        "  print_activations(pool2)\n",
        "  \n",
        "  with tf.name_scope('conv3') as scope:\n",
        "    kernel = tf.Variable(tf.truncated_normal([3,3,192,384],\n",
        "                                            dtype=tf.float32,stddev=1e-1),name='weights')\n",
        "    conv = tf.nn.conv2d(pool2,kernel,[1,1,1,1],padding='SAME')\n",
        "    biases = tf.Variable(tf.constant(0.0,shape=[384],dtype=tf.float32),trainable=True,name='biases')\n",
        "    bias = tf.nn.bias_add(conv,biases)\n",
        "    conv3 = tf.nn.relu(bias,name=scope)\n",
        "    parameters+=[kernel,biases]\n",
        "    print_activations(conv3)\n",
        "    \n",
        "  with tf.name_scope('conv4') as scope:\n",
        "    kernel = tf.Variable(tf.truncated_normal([3,3,384,256],\n",
        "                                            dtype=tf.float32,stddev=1e-1),name='weights')\n",
        "    conv = tf.nn.conv2d(conv3,kernel,[1,1,1,1],padding='SAME')\n",
        "    biases = tf.Variable(tf.constant(0.0,shape=[256],dtype=tf.float32),trainable=True,name='biases')\n",
        "    bias = tf.nn.bias_add(conv,biases)\n",
        "    conv4 = tf.nn.relu(bias,name=scope)\n",
        "    parameters+=[kernel,biases]\n",
        "    print_activations(conv4)\n",
        "    \n",
        "  with tf.name_scope('conv5') as scope:\n",
        "    kernel = tf.Variable(tf.truncated_normal([3,3,256,256],\n",
        "                                            dtype=tf.float32,stddev=1e-1),name='weights')\n",
        "    conv = tf.nn.conv2d(conv4,kernel,[1,1,1,1],padding='SAME')\n",
        "    biases = tf.Variable(tf.constant(0.0,shape=[256],dtype=tf.float32),trainable=True,name='biases')\n",
        "    bias = tf.nn.bias_add(conv,biases)\n",
        "    conv5 = tf.nn.relu(bias,name=scope)\n",
        "    parameters+=[kernel,biases]\n",
        "    print_activations(conv5)\n",
        "    \n",
        "  pool5 = tf.nn.max_pool(conv5,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID',name='pool5')\n",
        "  print_activations(pool5)\n",
        "  return pool5,parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KTDcrNHZP2nc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def time_tensorflow_run(session,target,info_string):\n",
        "  num_steps_burn_in = 10\n",
        "  total_duration = 0.0\n",
        "  total_duration_squared = 0.0\n",
        "  for i in range(num_batches+num_steps_burn_in):\n",
        "    start_time = time.time()\n",
        "    _ = session.run(target)\n",
        "    duration = time.time()-start_time\n",
        "    if i>=num_steps_burn_in:\n",
        "      if not i%10:\n",
        "        print('%s: step %d,duration = %.3f' %(datetime.now(),i-num_steps_burn_in,duration))\n",
        "        total_duration += duration\n",
        "        total_duration_squared += duration*duration\n",
        "  mn = total_duration/num_batches\n",
        "  vr = total_duration_squared/num_batches-mn*mn\n",
        "  sd = math.sqrt(vr)\n",
        "  print('%s; %s arcoss %d steps, %.3f +/- %.3f sec/batch'%(datetime.now(),info_string,num_batches,mn,sd))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lmdf2iMXYNmA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_benchmark():\n",
        "  with tf.Graph().as_default():\n",
        "    iamge_size = 224\n",
        "    images = tf.Variable(tf.random_normal([batch_size,iamge_size,iamge_size,3],dtype=tf.float32,stddev=1e-1))\n",
        "    pool5,parameters = inference(images)\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess = tf.Session()\n",
        "    sess.run(init)\n",
        "    \n",
        "    time_tensorflow_run(sess,pool5,\"Forward\")\n",
        "    \n",
        "    objective = tf.nn.l2_loss(pool5)\n",
        "    grad = tf.gradients(objective,parameters)\n",
        "    time_tensorflow_run(sess,grad,\"Forward-backward\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B9vKWW5fWCRx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "3fb29dd1-6f94-4ad9-a700-87680679fd2e"
      },
      "cell_type": "code",
      "source": [
        "run_benchmark()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1  [32, 56, 56, 64]\n",
            "pool1  [32, 27, 27, 64]\n",
            "conv2  [32, 27, 27, 192]\n",
            "pool2  [32, 13, 13, 192]\n",
            "conv3  [32, 13, 13, 384]\n",
            "conv4  [32, 13, 13, 256]\n",
            "conv5  [32, 13, 13, 256]\n",
            "pool5  [32, 6, 6, 256]\n",
            "2018-06-25 11:28:07.154413: step 0,duration = 0.048\n",
            "2018-06-25 11:28:07.626435: step 10,duration = 0.047\n",
            "2018-06-25 11:28:08.095971: step 20,duration = 0.047\n",
            "2018-06-25 11:28:08.566764: step 30,duration = 0.047\n",
            "2018-06-25 11:28:09.037563: step 40,duration = 0.047\n",
            "2018-06-25 11:28:09.507230: step 50,duration = 0.047\n",
            "2018-06-25 11:28:09.977306: step 60,duration = 0.047\n",
            "2018-06-25 11:28:10.446668: step 70,duration = 0.047\n",
            "2018-06-25 11:28:10.915580: step 80,duration = 0.047\n",
            "2018-06-25 11:28:11.385279: step 90,duration = 0.047\n",
            "2018-06-25 11:28:11.808336; Forward arcoss 100 steps, 0.005 +/- 0.014 sec/batch\n",
            "2018-06-25 11:28:13.629034: step 0,duration = 0.134\n",
            "2018-06-25 11:28:14.973700: step 10,duration = 0.134\n",
            "2018-06-25 11:28:16.316677: step 20,duration = 0.135\n",
            "2018-06-25 11:28:17.659406: step 30,duration = 0.134\n",
            "2018-06-25 11:28:19.004007: step 40,duration = 0.134\n",
            "2018-06-25 11:28:20.349030: step 50,duration = 0.134\n",
            "2018-06-25 11:28:21.691161: step 60,duration = 0.134\n",
            "2018-06-25 11:28:23.033926: step 70,duration = 0.135\n",
            "2018-06-25 11:28:24.378050: step 80,duration = 0.134\n",
            "2018-06-25 11:28:25.721470: step 90,duration = 0.134\n",
            "2018-06-25 11:28:26.932626; Forward-backward arcoss 100 steps, 0.013 +/- 0.040 sec/batch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_ViCPXtKHvrc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}